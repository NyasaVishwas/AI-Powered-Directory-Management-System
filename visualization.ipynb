{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a04a22-a01f-43e5-ad37-c162021e3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e92bbdb-a399-4eda-b942-280a4f4b4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryVisualizer:\n",
    "    @staticmethod\n",
    "    def get_files_and_folders(path):\n",
    "        \"\"\" Returns files and folders from the selected directory. \"\"\"\n",
    "        files = []\n",
    "        folders = {}\n",
    "\n",
    "        for root, dirs, filenames in os.walk(path):\n",
    "            for file in filenames:\n",
    "                ext = os.path.splitext(file)[-1].lower() or \"No Extension\"\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    size = os.path.getsize(file_path)\n",
    "                    created_time = os.path.getctime(file_path)\n",
    "                    files.append((file_path, ext, size, created_time))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            for folder in dirs:\n",
    "                folder_path = os.path.join(root, folder)\n",
    "                try:\n",
    "                    total_size = sum(os.path.getsize(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)))\n",
    "                    folders[folder] = total_size\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return files, folders\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_largest_files(path):\n",
    "        \"\"\" Creates a bar chart for the largest files. \"\"\"\n",
    "        files, _ = DirectoryVisualizer.get_files_and_folders(path)\n",
    "\n",
    "        if not files:\n",
    "            print(\"No files found in the selected directory.\")\n",
    "            return\n",
    "\n",
    "        sorted_files = sorted(files, key=lambda x: x[2], reverse=True)[:10]\n",
    "        file_names = [os.path.basename(f[0]) for f in sorted_files]\n",
    "        file_sizes = [f[2] / (1024 * 1024) for f in sorted_files]  # Convert to MB\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(file_names, file_sizes, color=\"orange\")\n",
    "        plt.xlabel(\"Files\")\n",
    "        plt.ylabel(\"Size (MB)\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Top 10 Largest Files\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_duplicate_files(path):\n",
    "        \"\"\" Detects and lists duplicate files based on their hash. \"\"\"\n",
    "        files, _ = DirectoryVisualizer.get_files_and_folders(path)\n",
    "        hash_map = {}\n",
    "\n",
    "        def hash_file(file_path):\n",
    "            \"\"\" Returns SHA-256 hash of the given file. \"\"\"\n",
    "            try:\n",
    "                hasher = hashlib.sha256()\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    while chunk := f.read(8192):\n",
    "                        hasher.update(chunk)\n",
    "                return hasher.hexdigest()\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        duplicates = {}\n",
    "        for file_path, _, _, _ in files:\n",
    "            file_hash = hash_file(file_path)\n",
    "            if file_hash:\n",
    "                if file_hash in hash_map:\n",
    "                    duplicates.setdefault(file_hash, []).append(file_path)\n",
    "                else:\n",
    "                    hash_map[file_hash] = file_path\n",
    "\n",
    "        # Display results\n",
    "        if duplicates:\n",
    "            print(\"\\nüîç Duplicate Files Found:\")\n",
    "            for file_hash, paths in duplicates.items():\n",
    "                print(f\"\\nHash: {file_hash}\")\n",
    "                for path in paths:\n",
    "                    print(f\" - {path}\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No duplicate files found.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_file_types_static(path):\n",
    "        \"\"\" Creates a pie chart for file type distribution. \"\"\"\n",
    "        files, _ = DirectoryVisualizer.get_files_and_folders(path)\n",
    "        ext_counts = Counter(ext for _, ext, _, _ in files)\n",
    "\n",
    "        if not ext_counts:\n",
    "            print(\"No files found in the selected directory.\")\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.pie(ext_counts.values(), labels=ext_counts.keys(), autopct=\"%1.1f%%\", colors=plt.cm.Paired.colors)\n",
    "        plt.title(\"File Type Distribution\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_folder_sizes_static(path):\n",
    "        \"\"\" Creates a bar chart for the largest folders. \"\"\"\n",
    "        _, folders = DirectoryVisualizer.get_files_and_folders(path)\n",
    "\n",
    "        if not folders:\n",
    "            print(\"No folders found in the selected directory.\")\n",
    "            return\n",
    "\n",
    "        sorted_folders = sorted(folders.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        folder_names, folder_sizes = zip(*sorted_folders)\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(folder_names, np.array(folder_sizes) / (1024 * 1024), color=\"blue\")\n",
    "        plt.xlabel(\"Folders\")\n",
    "        plt.ylabel(\"Size (MB)\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Top 10 Largest Folders\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_file_ages_static(path):\n",
    "        \"\"\" Creates a histogram showing file age distribution. \"\"\"\n",
    "        files, _ = DirectoryVisualizer.get_files_and_folders(path)\n",
    "        timestamps = [created_time for _, _, _, created_time in files]\n",
    "\n",
    "        if not timestamps:\n",
    "            print(\"No files found in the selected directory.\")\n",
    "            return\n",
    "\n",
    "        dates = [datetime.fromtimestamp(ts).date() for ts in timestamps]\n",
    "        date_counts = Counter(dates)\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(date_counts.keys(), date_counts.values(), color=\"green\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Number of Files\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"File Age Analysis\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc54918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook visualization.ipynb to script\n",
      "[NbConvertApp] Writing 5482 bytes to visualization.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script visualization.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
